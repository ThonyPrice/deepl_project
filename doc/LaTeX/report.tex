\documentclass{kthreport}

\usepackage{hhline}
\usepackage[parfill]{parskip}
\usepackage{subcaption}
\usepackage{placeins}

\pagestyle{plain}
\pagenumbering{arabic}


\title{Classification of ImageNet with Convolutional Neural Networks}
\subtitle{A study in techniques to improve CNN's}
\author{W. Skagerstr√∂m, T. Price, N. Lindqvist}
\diarienr{Deepl-18 Project}



\begin{document}
\maketitle
\newpage
\begin{abstract}

\noindent
This report is our final piece of work in the course DD2424, Deep Learning in Data Science. The overarching purpose is investigating convolutional neural networks (CNNs) while applying knowledge and techniques which we've acquired in during the course.
\noindent
To thoroughly investigate the topic a CNN will be constructed in the most vanilla way possible. The architecture will be based on research of state of the art and previous implementation on topic. The network will be optimized iteratively by more sophisticated initialization, changing activation functions and additional additional optimization and regularization such as dropout and batch normalization. The effect of each modification will be documented and analyzed. Lastly, the results is discussed on their own and in context of other ImageNet classifiers.
\end{abstract}
\newpage

\tableofcontents
\newpage

\section{Introduction}
Image classification is one of the main branches within Computer Vision. The task can be summarized as extracting features from a picture, which takes the shape of a pixel matrix containing either 1 or 3 channels (for gray-scale or red, green, and blue, respectively). Back in 2012, Convolutional Neural Networks (CNN's) began replacing the previously manually written algorithms for feature detection, and continue to hold the title as a state of the art method for image classification. The reason for the resurgence of CNN's was partly due to the winning entry of the AlexNet in the 2012 ImageNet competition \cite{krizhevsky2012imagenet}. Convolutional Neural Networks have existed for almost 20 years, but was previously limited by the availability of data and computer hardware. However, due to the great advancement of modern computers has enabled the ability to train increasingly deep and complex types of neural networks. In 2014, another progressive leap in the development of image classification occured with the itroduction of VGGNet and GoogleNet \cite{simonyan2014very}, \cite{szegedy2016rethinking}.  Due to the possibility of creating CNN's of varying architecture and size, a modern industry standard for evaluating the performance of a network is by benchmarking it through the ImageNet dataset \cite{russakovsky2015imagenet}.


\section{Previous work}
Among the many entries to the ImageNet classification challenge, deep convolution network architectures such AlexNet, VGGNet and GoogleNet have proven themselves to be highly effective and has created a renewed interesting in the development and optimization of such architectures. However, these different types of network comes with some individual strengths and weaknesses.

Text about previous work, references etc.

Useful citations:

AlexNet: \cite{krizhevsky2012imagenet}

VGGNet: \cite{simonyan2014very}

GoogleNet:\cite{szegedy2016rethinking}

\subsection{AlexNet}
AlexNet is the network architecture that renewed the industry interest in Convolutional Neural networks. AlexNet consists of a total of 8 layers, which are 5 convolutional layers which are stacked on eachother, followed by three fully connected layers. The network features two sets of of batch normalization, which are applied following each of the first two convolution layers, and a dropout occurs after each of the last two fully connected layers.
\subsection{GoogleNet}

\subsection{VGGNet}
\subsection{ResNet}
\subsection{SqueezeNet}



\section{Method}
\subsection{Dataset}
The data used was the ImageNet Tiny dataset, which is a reduced variant of the ImageNet set. The Tiny variation consists of 200 different classes. The resolution of the images has been reduced to $64\times64\times3$ (from  $224\times224\times3$). The dataset consists of 100 000 training samples, 10000 validation samples, and 10000 test samples.
\\\\
Below is a small sample of pictures included in the dataset:
\input{snippets/samples}
\FloatBarrier
Normalization of the input data occurs as two different methods: At first, some models are trained with data where the color channeles are divided by the maximum output of the RBG color palettes (255), resulting in the the colors being represented as numbers in ${\rm I\!R} \in [0,1]$.
This was later changed to using Batch Normalization instead for the later training iterations.

\subsection{Data Augmentation}
An additional feature that was later added in order to improve the accuracy of the network was data augmentation. The methods of augmentation are the following:

\begin{itemize}
  \item \textbf{Featurewise center:} Set mean of all inputs to 0.
  \item \textbf{Whitening (ZCA):} Applying whitening, may strengthen structure of objects in image.
  \item \textbf{Horizontal flip:} New perspective on images naturally expands the training data. Vertical flip is available too but in many of the classes an upside-down representation has low resemblance to the image class.
  \item \textbf{Shift:} Shifting images horizontally and vertically allows images to appear in different regions of input space which allows for better generalization.
\end{itemize}
Data augmentation was applied batch by batch for each batch used in the training process.

\subsection{Implementing a CNN}

\subsubsection{Implementation specifics}

The network was written and implemented in Python 3.5.2, using the Keras Framework which runs on top of Tensorflow. Numpy was used for data management and Matplotlib to create the graphs. To assist in training and evaluating the networks, we used Google Cloud services for computation power. The specifications of the hardware used was:
\begin{itemize}
\item 1 x NVIDIA Tesla K80
\item An unspecified dual core CPU (Unknown CPU Platform on the Google Cloud Platform).
\item 16 GB RAM memory
\item 40 GB Disk space.
\end{itemize}

\subsubsection{Evaluating architectures}

The basis of the CNN architecture is inspired by \cite{NIPS2012_4824}, it is summarized in figure \ref{fig:architecture}. However, it was implemented on the full ImageNet dataset. Inspired by \textbf{insert 3 reports here} we decided to test three configurations, summarized in \ref{table:3_configurations}.

\input{snippets/fig_architecture}
\FloatBarrier

\input{snippets/3_configurations}
\FloatBarrier


Tests was run with \textbf{insert how tests were run} iterations. Training was done on the entire Tiny Imagenet dataset, containing 100 000 images and their respective labels. The composition of the dataset is 200 classes with 500 images each. The training data is shuffled before the training process begins. For evaluation, the entire validation dataset was used, containing 10000 images. The results of each architecture is presented in section...

\subsubsection{Initialization matters}

Details about the different parts of the network.\\
Weight initialization.\\
Optimizer.\\
Learning rate.\\
Loss function.\\




\subsubsection{Training and evaluation}
The network was trained on the entire Tiny ImageNet dataset, consisting of the 100 000 pictures, for \textbf{NUMBER OF EPOCHS}. Some of the later iterations of training also included data augmentation methods listed in \textbf{WHERE DATA AUGMENTATION SECTION IS}.

\section{Results}
Graphs/Tables of trainloss, valloss, accuracies etc.

\section{Discussion}

\subsection{Evaluation of method}
Thoughts about the method.

\subsection{Evaluation of results}

Thoughts about the result.

\subsection{ImageNet state of the art}

Comparing ours to other state of the art networks.

\section{Conclusion}
Final thoughts, future research, improvements etc.

\bibliography{references}{}
\bibliographystyle{plain}

\end{document}
